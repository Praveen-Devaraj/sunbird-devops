#jinja2:lstrip_blocks: True
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: maintainance-proxy-default
  namespace: {{ namespace }}
data:
  proxy-default.conf: |+
  {% if proto=='https' %}
    server {
      listen 80;
      listen [::]:80;
      server_name {{ proxy_server_name }};
      {#
      custom nginx server config section
      eg:
      nginx_server_config: |
        if ($allowed_country = no) {
            return 444;
        }
      #}
      # Limitting open connection per ip
      limit_conn limitbyaddr {{ nginx_per_ip_connection_limit }};
      return 301 https://{{ proxy_server_name }}$request_uri;
    }
  {% endif %}
    server {
      {% if proto=='http' %}
        listen                80;
        listen    [::]:80;
      {% else %}
        listen                443 ssl;
        ssl_certificate       /etc/secrets/site.crt;
        ssl_certificate_key   /etc/secrets/site.key;
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers "EECDH+ECDSA+AESGCM EECDH+aRSA+AESGCM EECDH+ECDSA+SHA384 EECDH+ECDSA+SHA256 EECDH+aRSA+SHA384 EECDH+aRSA+SHA256 EECDH+aRSA+RC4 EECDH EDH+aRSA HIGH !RC4 !aNULL !eNULL !LOW !3DES !MD5 !EXP !PSK !SRP !DSS";
      {% endif  %}
        server_name *.{{ proxy_server_name }} {{ proxy_server_name }};
        {#
        custom nginx server config section
        eg:
        nginx_server_config: |
          if ($allowed_country = no) {
              return 444;
          }
        #}
        # Limitting open connection per ip
        limit_conn limitbyaddr {{ nginx_per_ip_connection_limit }};
        proxy_set_header    Host              $host;
        proxy_set_header    X-Real-IP         {{ nginx_client_public_ip_header | d('$remote_addr') }};
        proxy_set_header    X-Forwarded-SSL   on;
        proxy_set_header    X-Forwarded-Proto $scheme;
        ignore_invalid_headers off;  #pass through headers from Jenkins which are considered invalid by Nginx server.
        resolver {{ kube_dns_ip }} valid=30s;

        root /usr/share/nginx/html;
        index index.html;

        location / {
          try_files $uri $uri/ /index.html;
        }

        location /api {
          return 531;
        }

        location /grafana/ {
          set $target http://prometheus-operator-grafana.monitoring.svc.cluster.local;
          rewrite ^/grafana/(.*) /$1 break;
          proxy_pass $target;
        }

       location ~* ^/auth/v1/refresh/token  {
          return 531;
        }

        client_max_body_size 60M;
      }

---
# Source: nginx-public-ingress/templates/configMap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: maintainance-nginx-conf
  namespace: {{ namespace }}
data:
  nginx.conf: |+
    user  nginx;
    worker_processes  1;
      load_module modules/ngx_http_geoip2_module.so;

    error_log  /var/log/nginx/error.log warn;
    pid        /var/run/nginx.pid;
    events {
        worker_connections  10000;
    }
    http {
        include       /etc/nginx/mime.types;
        default_type  application/octet-stream;
        resolver 172.19.0.10 valid=30s;
           geoip2 /usr/local/share/GeoIP/GeoIP2-Country.mmdb {
             $geoip2_data_country_iso_code country iso_code;
         }
         map $geoip2_data_country_iso_code $allowed_country {
         default no;
             IN  yes;
         }

        lua_load_resty_core off;
        log_format  main  '$remote_addr - $remote_user [$time_local] '
                          '"$request" $status $body_bytes_sent '
                          '$request_time $upstream_response_time $pipe'
                          '"$http_referer" "$http_user_agent"';

        access_log  /var/log/nginx/access.log  main;

        # Shared dictionary to store metrics
        lua_shared_dict prometheus_metrics 100M;
        lua_package_path "/etc/nginx/lua_modules/?.lua";

        # Defining upstream cache status for nginx metrics
        map $upstream_cache_status $cache_status {
          default  $upstream_cache_status;
          ''       "NONE";
        }

        # Defining metrics
        init_worker_by_lua_block {
          prometheus = require("prometheus").init("prometheus_metrics")
          metric_requests = prometheus:counter(
            "nginx_http_requests_total", "Number of HTTP requests", {"host", "status", "request_method", "cache_status"})
          metric_latency = prometheus:histogram(
            "nginx_http_request_duration_seconds", "HTTP request latency", {"host"})
          metric_connections = prometheus:gauge(
            "nginx_http_connections", "Number of HTTP connections", {"state"})
        }
        log_by_lua_block {
          metric_requests:inc(1, {ngx.var.server_name, ngx.var.status, ngx.var.request_method, ngx.var.cache_status })
          metric_latency:observe(tonumber(ngx.var.request_time), {ngx.var.server_name})
        }

        header_filter_by_lua_block {
         ngx.header["server"] = nil
        }

        sendfile        on;
        #tcp_nopush     on;
        client_max_body_size 60M;

        keepalive_timeout  65s;
        keepalive_requests 200;

        # Nginx connection limit per ip
        limit_conn_zone $binary_remote_addr zone=limitbyaddr:10m;
        limit_conn_status 429;

        include /etc/nginx/conf.d/*.conf;

        # local caching for images and files
        proxy_cache_path /tmp/proxy_cache levels=1:2 keys_zone=tmp_cache:5m max_size=10m inactive=60m use_temp_path=off;

        proxy_cache_path /tmp/api_cache levels=1:2 keys_zone=proxy_cache:5m max_size=300m inactive=60m use_temp_path=off;
        # cache framework
        proxy_cache_path /tmp/framework_cache levels=1:2 keys_zone=framework_cache:5m max_size=700m inactive=60m use_temp_path=off;

       server {
         listen 9145;
         location /metrics {
           content_by_lua_block {
              metric_connections:set(ngx.var.connections_reading, {"reading"})
              metric_connections:set(ngx.var.connections_waiting, {"waiting"})
              metric_connections:set(ngx.var.connections_writing, {"writing"})
              prometheus:collect()
            }
         }
       }
    }

---
apiVersion: v1
kind: ConfigMap
metadata:
  namespace: {{ namespace }}
  name: maintainance-index-conf
data:
  index.html: |+
{{ lookup('file', "templates/index.html") | indent(width=4,indentfirst=True) }}


---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: maintainance-nginx-ingress
  namespace: {{ namespace }}
spec:
  replicas: 1
  selector:
    matchLabels:
      app: maintainance-nginx-ingress
  template:
    metadata:
      labels:
        app: maintainance-nginx-ingress
    spec:
      volumes:
      - name: tls
        secret:
          secretName: ingress-cert
      - name: proxy-config
        configMap:
          name: maintainance-proxy-default
      - name: nginx-config
        configMap:
          name: maintainance-nginx-conf
      - name: index-config
        configMap:
          name: maintainance-index-conf
      - name: banner-config
        configMap:
          name: banner-image
      - name: logo-config
        configMap:
          name: logo-image
      imagePullSecrets:
      - name: {{ imagepullsecrets }}
      containers:
      - name: maintainance-nginx-ingress
        image: "{{ dockerhub }}/proxy:release-3.0.0_RC7_7"
        imagePullPolicy: IfNotPresent
        volumeMounts:
          - name: tls
            mountPath: /etc/secrets
            readOnly: true
          - name: proxy-config
            mountPath: /etc/nginx/conf.d/default.conf
            subPath: proxy-default.conf
            readOnly: true
          - name: nginx-config
            mountPath: /etc/nginx/nginx.conf
            subPath: nginx.conf
            readOnly: true
          - name: index-config
            mountPath: /usr/share/nginx/html/index.html
            subPath: index.html
            readOnly: true 
          - name: banner-config
            mountPath: /usr/share/nginx/html/banner-img.png
            subPath: banner-img.png
            readOnly: true 
          - name: logo-config
            mountPath: /usr/share/nginx/html/Diksha-logo.png
            subPath: Diksha-logo.png
            readOnly: true 
        resources:
          requests:
            cpu: 100m
            memory: 200Mi
        ports:
        - containerPort: 80
          name: http
        - containerPort: 443
          name: https
        - containerPort: 9145
          name: http-metrics
